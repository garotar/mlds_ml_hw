Описание домашнего задания № 1

Что было сделано:

1. Произведен разведочный анализ данных, в ходе которого:

      1.1 были обработаны пропуски;
   
      1.2 были обработаны колонки с категориальными переменными (в т.ч. разделение колонки 'torque' на 2 разные);
  
      1.3 были построены графики, показывающие корреляцию между числовыми признаками.

2. Обучение модели линейной регрессии:
   
      2.1 на вещественных признаках с дефолтными параметрами (коэффициент детерминации на тесте = 0.6004);
   
      2.2 на вещественных признаках с масштабированием (коэффициент детерминации на тесте = 0.5731);
  
      2.3 с L1-регуляризацией на вещественных признаках с масштабированием (коэффициент детерминации на тесте = 0.5731);
  
      2.4 с подбором оптимальных гиперпараметров с помощью GridSearchCV для L1-регуляризации (коэффициент детерминации на тесте = 0.5463);
  
      2.5 с подбором оптимальных гиперпараметров с помощью GridSearchCV для ElasticNet (коэффициент детерминации на тесте = 0.5463);
  
      2.6 с L2-регуляризацией на всех признаках (коэффициент детерминации на тесте = 0.6524).

3. Feature Engineering и обучение модели линейной регрессии с подбором оптимальных гиперпараметров с помощью GridSearchCV для L2-регуляризации.
   Наибольший буст в качестве дал Feature Engineering, коэффициент детерминации на тесте вырос до 0.9148.

4. Рассчитана кастомная бизнес-метрика, которая выдала 100% точность модели.

5. Реализован сервис на FastAPI.

Что НЕ БЫЛО сделано:

1. В части Feature Engineering очень хотелось добавить полиномиальные признаки с помощью sklearn.preprocessing.PolynomialFeatures. Однако, при добавлении этих признаков качество модели резко падало: коэффициент детерминации на тесте становился отрицательным, что говорило о сильном переобучении модели.

2. Не были проанализированы выбросы в данных.

3. Не были добавлены некоторы "полезные" признаки. Например, признак: 'число "лошадей" на литр объема'.
